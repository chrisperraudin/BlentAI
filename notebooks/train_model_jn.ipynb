{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98aed86-143c-4104-a315-3febf7dca790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "import importlib\n",
    "\n",
    "# Ajouter le chemin absolu du dossier 'config'\n",
    "sys.path.append('../config')\n",
    "sys.path.append('../src')\n",
    "# Importer le module de configuration\n",
    "import config\n",
    "# Recharger le module de configuration pour prendre en compte les modifications\n",
    "importlib.reload(config)\n",
    "# Utiliser la configuration\n",
    "cfg = config.cfg\n",
    "\n",
    "\n",
    "# Importer\n",
    "from config import cfg\n",
    "from model_unet import build_model_UNET\n",
    "from common_utils import load_normalize_images, load_rgb2mask_labels\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def display_loss_acc(res_list):\n",
    "    \"\"\"Afficher les courbes de perte et de précision\"\"\"\n",
    "    \n",
    "    # Initialiser les listes pour stocker la perte et la précision\n",
    "    loss = []\n",
    "    accuracy = []\n",
    "\n",
    "    # Parcourir chaque objet History dans la liste\n",
    "    for res in res_list:\n",
    "        loss.extend(res['loss'])\n",
    "        accuracy.extend(res['accuracy'])\n",
    "        \n",
    "    \"\"\"Afficher les courbes de perte et de précision\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(res['loss'])\n",
    "    plt.title('Perte (Loss)')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Perte')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(res['accuracy'])  # Utilisez 'acc' pour la précision\n",
    "    plt.title('Précision (Accuracy)')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Précision')\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model):\n",
    "    \"\"\"Params : \n",
    "        model = model UNET\n",
    "        train_img_list_norm = liste images to train\n",
    "        train_label_list = liste mask images to train\n",
    "        batch_size = taille du batch\n",
    "        epochs = nbre epochs\n",
    "    \"\"\"\n",
    "    # Définir les rappels\n",
    "    callbacks = [\n",
    "    EarlyStopping(patience=5, verbose=1),\n",
    "    ModelCheckpoint('../model/' + cfg['MODEL_NAME'] , verbose=1, save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    # Nombre d'images à traiter à chaque itération\n",
    "    slice_size = cfg['NB_IMG_BY_TRAIN_FIT'] #140 ok\n",
    "    \n",
    "    # Nombre d'epochs à effectuer\n",
    "    num_epochs = cfg['UNET_EPOCHS']\n",
    "    \n",
    "    validation_split = cfg['SPLIT_VALID']/100\n",
    "    \n",
    "    # Nombre total d'images dans l'ensemble de données d'entraînement et de validation\n",
    "    total_train_images = len([name for name in os.listdir(cfg['TRAIN_DIR'] + cfg['OUTPUT_DIR_IMAGE']) if os.path.isfile(os.path.join(cfg['TRAIN_DIR'] + cfg['OUTPUT_DIR_IMAGE'], name))])\n",
    "    total_val_images = len([name for name in os.listdir(cfg['VALID_DIR'] + cfg['OUTPUT_DIR_IMAGE']) if os.path.isfile(os.path.join(cfg['VALID_DIR'] + cfg['OUTPUT_DIR_IMAGE'], name))])\n",
    "\n",
    "    # total_train_images = 5000\n",
    "    # total_val_images = int(total_train_images * validation_split)\n",
    "\n",
    "    # Accumuler les résultats des batches\n",
    "    results = []\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "   \n",
    "        # Boucle sur les tranches d'images\n",
    "        for i in range(0, total_train_images, slice_size):\n",
    "            # Sélectionnez la tranche d'images à utiliser pour cet itération\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - tranche {i+1}/{i+slice_size}\")\n",
    "            \n",
    "            # Charger et traiter les données par batch\n",
    "            epoch_train_images = []\n",
    "            epoch_train_labels = []\n",
    "            epoch_val_images = []\n",
    "            epoch_val_labels = []\n",
    "            \n",
    "            # Charger et normaliser les images d'entraînement + labelliser\n",
    "            train_img_list_norm = load_normalize_images(cfg['TRAIN_DIR'], i, min(i + slice_size, total_train_images))\n",
    "            train_label_list = load_rgb2mask_labels(cfg['TRAIN_DIR'], i, min(i + slice_size, total_train_images))\n",
    "\n",
    "            # Calculer la tranche pour les images de validation\n",
    "            val_slice_size = int(slice_size * validation_split)\n",
    "            val_start_index = (i // slice_size) * val_slice_size\n",
    "            val_end_index = min(val_start_index + val_slice_size, total_val_images)\n",
    "            \n",
    "            val_img_list_norm = load_normalize_images(cfg['VALID_DIR'], val_start_index, val_end_index)\n",
    "            val_label_list = load_rgb2mask_labels(cfg['VALID_DIR'], val_start_index, val_end_index)\n",
    "                     \n",
    "            # Convertir les labels en one-hot encoding\n",
    "            train_label = to_categorical(np.array(train_label_list), num_classes=3)\n",
    "            val_label = to_categorical(np.array(val_label_list), num_classes=3)\n",
    "           \n",
    "            # Accumulez les tranches dans les listes\n",
    "            epoch_train_images.extend(train_img_list_norm)\n",
    "            epoch_train_labels.extend(train_label)\n",
    "            epoch_val_images.extend(val_img_list_norm)\n",
    "            epoch_val_labels.extend(val_label)\n",
    "    \n",
    "            # Convertir les listes accumulées en arrays numpy\n",
    "            epoch_train_images = np.array(epoch_train_images, dtype=np.float32)\n",
    "            epoch_train_labels = np.array(epoch_train_labels, dtype=np.float32)\n",
    "            epoch_val_images = np.array(epoch_val_images, dtype=np.float32)\n",
    "            epoch_val_labels = np.array(epoch_val_labels, dtype=np.float32)\n",
    "  \n",
    "            # Entraîner le modèle sur toutes les tranches accumulées pour cette epoch\n",
    "            result = model.fit(\n",
    "                epoch_train_images, epoch_train_labels,\n",
    "                batch_size=cfg['UNET_BATCH_SIZE'], \n",
    "                epochs=1,\n",
    "                verbose=1,\n",
    "                callbacks=callbacks,\n",
    "                validation_data=(epoch_val_images, epoch_val_labels)\n",
    "            )\n",
    "        \n",
    "        # Append the loss and accuracy for each slice\n",
    "        epoch_loss.append(result.history['loss'])\n",
    "        epoch_accuracy.append(result.history['accuracy'])\n",
    "        \n",
    "        # Libérer la mémoire des variables non utilisées\n",
    "        del epoch_train_images, epoch_train_labels, epoch_val_images, epoch_val_labels\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Afficher l'utilisation de la mémoire GPU\n",
    "        # print_gpu_utilization()\n",
    "        \n",
    "    # Append the loss and accuracy for each epoch\n",
    "    results.append({'loss': epoch_loss, 'accuracy': epoch_accuracy})\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "#Chargement du model UNET 2Ds\n",
    "model = build_model_UNET()\n",
    "\n",
    "\n",
    "# Libérer la mémoire des variables non utilisées\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# Entrainement du model\n",
    "results = train_model(model)\n",
    "\n",
    "display_loss_acc(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451b480-6a9c-4cfb-99cc-70789360b367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
